{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks EMNLP 2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1前言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1课程回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='imgs/overall_pcnn.png' width=\"800\" height=\"800\" align=\"bottom\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 模型结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/model.png\"  width=\"600\" height=\"600\" align=\"bottom\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 代码结构"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./imgs/dir.png\"  width=\"300\" height=\"300\" align=\"bottom\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 准备工作\n",
    "### 2.1项目环境配置\n",
    "\n",
    "* Python3.8\n",
    "* jupyter notebook\n",
    "* torch            1.6.0+cu10.2\n",
    "* numpy            1.18.5\n",
    "\n",
    "代码运行环境建议使用Visual Studio Code(VScode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 数据集下载"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据集下载地址链接：https://pan.baidu.com/s/1BaBYvvxWO8IwTSi-GEqUaA <br>\n",
    "提取码：0d23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 项目代码结构（VScode中演示）\n",
    "\n",
    ">1）是什么？\n",
    "\n",
    "　　我们首先会在VScode环境中让代码跑一下，直观感受到项目的训练，并展示前向推断的输出，让大家看到模型的效果。\n",
    ">2）怎么构成的？\n",
    "\n",
    "　　然后介绍项目代码的构成，介绍项目有哪些文件夹，包含哪些文件，这些文件构成了什么功能模块如：数据预处理模块，模型设计模块，损失函数模块，推断与评估模块。\n",
    ">3）小结\n",
    "\n",
    "　　在主文件中在过一下启动训练的流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 算法模块及细节（jupyter和VScode中演示）\n",
    "\n",
    "　　在jupyter notebook中细致地讲解每一个模块。\n",
    "  \n",
    "　　以实现模块功能为目的，来讲解每个函数的执行流程，呈现中间数据，方便同学们理解学习。\n",
    "  \n",
    "　　内容分为以下几个模块：**超参数设置，数据读取与处理，模型定义，模型训练，模型评价**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import models\n",
    "import dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils import save_pr, now, eval_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 超参数设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dic ={\n",
    "    'NYT': {\n",
    "        'data_root': './dataset/NYT/',\n",
    "        'w2v_path': './dataset/NYT/w2v.npy',\n",
    "        'p1_2v_path': './dataset/NYT/p1_2v.npy',\n",
    "        'p2_2v_path': './dataset/NYT/p2_2v.npy',\n",
    "        'vocab_size': 114043,\n",
    "        'rel_num': 53\n",
    "    },\n",
    "    'FilterNYT': {\n",
    "        'data_root': './dataset/FilterNYT/',\n",
    "        'w2v_path': './dataset/FilterNYT/w2v.npy',\n",
    "        'p1_2v_path': './dataset/FilterNYT/p1_2v.npy',\n",
    "        'p2_2v_path': './dataset/FilterNYT/p2_2v.npy',\n",
    "        'vocab_size': 160695 + 2,\n",
    "        'rel_num': 27\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultConfig(object):\n",
    "\n",
    "    model = 'PCNN_ONE'  # the name of used model, in  <models/__init__.py>\n",
    "    data = 'FilterNYT'  # SEM NYT FilterNYT\n",
    "\n",
    "    result_dir = './out'\n",
    "    data_root = data_dic[data]['data_root']  # the data dir\n",
    "    w2v_path = data_dic[data]['w2v_path']\n",
    "    p1_2v_path = data_dic[data]['p1_2v_path']\n",
    "    p2_2v_path = data_dic[data]['p2_2v_path']\n",
    "    load_model_path = 'checkpoints/model.pth'  # the trained model\n",
    "\n",
    "    seed = 3435\n",
    "    batch_size = 128  # batch size\n",
    "    use_gpu = True  # user GPU or not\n",
    "    gpu_id = 1\n",
    "    num_workers = 0  # how many workers for loading data\n",
    "\n",
    "    max_len = 80 + 2  # max_len for each sentence + two padding\n",
    "    limit = 50  # the position range <-limit, limit>\n",
    "\n",
    "    vocab_size = data_dic[data]['vocab_size']  # vocab + UNK + BLANK\n",
    "    rel_num = data_dic[data]['rel_num']\n",
    "    word_dim = 50\n",
    "    pos_dim = 5\n",
    "    pos_size = limit * 2 + 2\n",
    "\n",
    "    norm_emb=True\n",
    "\n",
    "    num_epochs = 16  # the number of epochs for training\n",
    "    drop_out = 0.5\n",
    "    lr = 0.0003  # initial learning rate\n",
    "    lr_decay = 0.95  # when val_loss increase, lr = lr*lr_decay\n",
    "    weight_decay = 0.0001  # optimizer parameter\n",
    "\n",
    "    # Conv\n",
    "    filters = [3]\n",
    "    filters_num = 230\n",
    "    sen_feature_dim = filters_num\n",
    "\n",
    "    rel_dim = filters_num * len(filters)\n",
    "    rel_filters_num = 100\n",
    "\n",
    "    print_opt = 'DEF'\n",
    "    use_pcnn=True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(self, kwargs):\n",
    "    '''\n",
    "    user can update the default hyperparamter\n",
    "    '''\n",
    "    for k, v in kwargs.items():\n",
    "        if not hasattr(self, k):\n",
    "            raise Exception('opt has No key: {}'.format(k))\n",
    "        setattr(self, k, v)\n",
    "    data_list = ['data_root', 'w2v_path', 'rel_num', 'vocab_size', 'p1_2v_path', 'p2_2v_path']\n",
    "    for r in data_list:\n",
    "        setattr(self, r, data_dic[self.data][r])\n",
    "\n",
    "    print('*************************************************')\n",
    "    print('user config:')\n",
    "    for k, v in self.__class__.__dict__.items():\n",
    "        if not k.startswith('__'):\n",
    "            print(\"{} => {}\".format(k, getattr(self, k)))\n",
    "\n",
    "    print('*************************************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DefaultConfig.parse = parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = DefaultConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************\n",
      "user config:\n",
      "model => PCNN_ONE\n",
      "data => FilterNYT\n",
      "result_dir => ./out\n",
      "data_root => ./dataset/FilterNYT/\n",
      "w2v_path => ./dataset/FilterNYT/w2v.npy\n",
      "p1_2v_path => ./dataset/FilterNYT/p1_2v.npy\n",
      "p2_2v_path => ./dataset/FilterNYT/p2_2v.npy\n",
      "load_model_path => checkpoints/model.pth\n",
      "seed => 3435\n",
      "batch_size => 128\n",
      "use_gpu => True\n",
      "gpu_id => 1\n",
      "num_workers => 0\n",
      "max_len => 82\n",
      "limit => 50\n",
      "vocab_size => 160697\n",
      "rel_num => 27\n",
      "word_dim => 50\n",
      "pos_dim => 5\n",
      "pos_size => 102\n",
      "norm_emb => True\n",
      "num_epochs => 16\n",
      "drop_out => 0.5\n",
      "lr => 0.0003\n",
      "lr_decay => 0.95\n",
      "weight_decay => 0.0001\n",
      "filters => [3]\n",
      "filters_num => 230\n",
      "sen_feature_dim => 230\n",
      "rel_dim => 230\n",
      "rel_filters_num => 100\n",
      "print_opt => DEF\n",
      "use_pcnn => True\n",
      "parse => <bound method parse of <__main__.DefaultConfig object at 0x7f55ccf07340>>\n",
      "*************************************************\n"
     ]
    }
   ],
   "source": [
    "opt.parse(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 数据读取与处理\n",
    "* 数据处理细节\n",
    "* 构建dataset类"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1数据处理细节"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 载入原始数据集并且预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_path = os.path.join(opt.data_root, 'vector.txt')\n",
    "word_path = os.path.join(opt.data_root, 'dict.txt')\n",
    "train_path = os.path.join(opt.data_root, 'train', 'train.txt')\n",
    "test_path = os.path.join(opt.data_root, 'test', 'test.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "载入word2vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist = []\n",
    "vecs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist.append('BLANK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "wlist = [word.strip('\\n') for word in open(word_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[',',\n",
       " 'the',\n",
       " '.',\n",
       " 'of',\n",
       " 'to',\n",
       " 'a',\n",
       " 'and',\n",
       " \"''\",\n",
       " 'in',\n",
       " 'that',\n",
       " \"'s\",\n",
       " 'for',\n",
       " 'is',\n",
       " 'The',\n",
       " 'said',\n",
       " 'on',\n",
       " 'was',\n",
       " 'with',\n",
       " 'at',\n",
       " 'he',\n",
       " 'Mr.',\n",
       " 'it',\n",
       " 'as',\n",
       " 'by',\n",
       " 'his',\n",
       " 'from',\n",
       " 'be',\n",
       " 'are',\n",
       " 'have',\n",
       " 'not',\n",
       " 'I',\n",
       " 'an',\n",
       " 'has',\n",
       " 'who',\n",
       " '$',\n",
       " ':',\n",
       " 'had',\n",
       " 'they',\n",
       " '``',\n",
       " 'or',\n",
       " 'their',\n",
       " 'would',\n",
       " '-RRB-',\n",
       " '-LRB-',\n",
       " 'were',\n",
       " 'will',\n",
       " 'but',\n",
       " 'this',\n",
       " '--',\n",
       " 'about',\n",
       " 'more',\n",
       " 'which',\n",
       " 'one',\n",
       " 'been',\n",
       " 'its',\n",
       " 'But',\n",
       " ';',\n",
       " 'In',\n",
       " 'It',\n",
       " \"n't\",\n",
       " 'He',\n",
       " 'her',\n",
       " 'than',\n",
       " 'you',\n",
       " 'when',\n",
       " 'up',\n",
       " 'out',\n",
       " 'all',\n",
       " 'she',\n",
       " 'do',\n",
       " 'two',\n",
       " 'we',\n",
       " 'like',\n",
       " 'can',\n",
       " 'years',\n",
       " 'other',\n",
       " 'last',\n",
       " 'A',\n",
       " 'also',\n",
       " 'there',\n",
       " 'year',\n",
       " 'into',\n",
       " 'people',\n",
       " \"'\",\n",
       " 'new',\n",
       " 'some',\n",
       " 'first',\n",
       " 'them',\n",
       " 'after',\n",
       " 'what',\n",
       " 'time',\n",
       " 'could',\n",
       " 'no',\n",
       " 'so',\n",
       " 'over',\n",
       " 'only',\n",
       " 'if',\n",
       " 'most',\n",
       " '?',\n",
       " 'him',\n",
       " 'percent',\n",
       " 'did',\n",
       " 'because',\n",
       " 'million',\n",
       " 'We',\n",
       " 'many',\n",
       " 'now',\n",
       " 'And',\n",
       " 'New_York',\n",
       " 'just',\n",
       " 'Ms.',\n",
       " 'American',\n",
       " 'company',\n",
       " 'where',\n",
       " 'made',\n",
       " 'through',\n",
       " 'They',\n",
       " 'three',\n",
       " 'before',\n",
       " 'even',\n",
       " 'much',\n",
       " 'say',\n",
       " 'make',\n",
       " '-',\n",
       " 'way',\n",
       " 'any',\n",
       " 'work',\n",
       " 'those',\n",
       " 'my',\n",
       " 'get',\n",
       " 'today',\n",
       " '\\\\*',\n",
       " 'may',\n",
       " 'our',\n",
       " 'This',\n",
       " '3',\n",
       " 'then',\n",
       " 'how',\n",
       " 'against',\n",
       " 'back',\n",
       " 'state',\n",
       " 'here',\n",
       " 'There',\n",
       " 'United_States',\n",
       " 'officials',\n",
       " 'down',\n",
       " 'off',\n",
       " 'being',\n",
       " 'still',\n",
       " 'city',\n",
       " 'should',\n",
       " 'week',\n",
       " 'That',\n",
       " 'well',\n",
       " 'very',\n",
       " '10',\n",
       " 'me',\n",
       " 'between',\n",
       " 'day',\n",
       " 'Dr.',\n",
       " 'since',\n",
       " 'home',\n",
       " 'If',\n",
       " 'these',\n",
       " 'For',\n",
       " 'good',\n",
       " 'going',\n",
       " 'does',\n",
       " 'own',\n",
       " 'another',\n",
       " \"'re\",\n",
       " 'President',\n",
       " 'yesterday',\n",
       " 'take',\n",
       " 'next',\n",
       " 'part',\n",
       " 'while',\n",
       " 'too',\n",
       " 'such',\n",
       " 'president',\n",
       " 'public',\n",
       " 'She',\n",
       " '1',\n",
       " 'both',\n",
       " 'under',\n",
       " 'think',\n",
       " 'go',\n",
       " 'As',\n",
       " 'world',\n",
       " 'long',\n",
       " 'might',\n",
       " 'children',\n",
       " '`',\n",
       " 'When',\n",
       " 'life',\n",
       " 'money',\n",
       " 'know',\n",
       " 'Street',\n",
       " 'game',\n",
       " 'few',\n",
       " 'ago',\n",
       " 'including',\n",
       " 'never',\n",
       " 'four',\n",
       " 'called',\n",
       " 'want',\n",
       " 'At',\n",
       " 'group',\n",
       " 'each',\n",
       " 'around',\n",
       " 'same',\n",
       " 'family',\n",
       " 'business',\n",
       " 'see',\n",
       " 'former',\n",
       " 'director',\n",
       " 'right',\n",
       " 'school',\n",
       " 'team',\n",
       " 'little',\n",
       " 'To',\n",
       " 'show',\n",
       " 'country',\n",
       " 'says',\n",
       " 'come',\n",
       " 'used',\n",
       " '2',\n",
       " 'left',\n",
       " 'market',\n",
       " 'night',\n",
       " 'play',\n",
       " 'end',\n",
       " 'season',\n",
       " 'us',\n",
       " 'use',\n",
       " 'On',\n",
       " 'You',\n",
       " 'political',\n",
       " 'during',\n",
       " 'several',\n",
       " 'found',\n",
       " 'until',\n",
       " 'second',\n",
       " 'days',\n",
       " 'program',\n",
       " 'companies',\n",
       " 'police',\n",
       " 'case',\n",
       " 'man',\n",
       " 'place',\n",
       " 'your',\n",
       " 'without',\n",
       " 'set',\n",
       " 'came',\n",
       " 'best',\n",
       " 'old',\n",
       " 'less',\n",
       " 'among',\n",
       " 'women',\n",
       " 'put',\n",
       " 'five',\n",
       " 'His',\n",
       " 'members',\n",
       " 'months',\n",
       " 'every',\n",
       " 'One',\n",
       " 'billion',\n",
       " 'law',\n",
       " 'told',\n",
       " 'high',\n",
       " 'early',\n",
       " \"'m\",\n",
       " '...',\n",
       " 'whose',\n",
       " 'State',\n",
       " '&',\n",
       " 'Bush',\n",
       " 'office',\n",
       " 'took',\n",
       " 'help',\n",
       " 'become',\n",
       " '20',\n",
       " 'With',\n",
       " 'Government',\n",
       " 'month',\n",
       " 'got',\n",
       " 'system',\n",
       " 'far',\n",
       " 'small',\n",
       " 'often',\n",
       " \"'ve\",\n",
       " 'lot',\n",
       " '30',\n",
       " 'government',\n",
       " 'least',\n",
       " '5',\n",
       " 'After',\n",
       " 'whether',\n",
       " 'something',\n",
       " 'began',\n",
       " 'recent',\n",
       " 'later',\n",
       " 'executive',\n",
       " 'need',\n",
       " 'better',\n",
       " 'music',\n",
       " 'number',\n",
       " 'major',\n",
       " 'Federal',\n",
       " 'away',\n",
       " 'men',\n",
       " 'Mrs.',\n",
       " 'THE',\n",
       " 'run',\n",
       " 'plan',\n",
       " 'big',\n",
       " 'What',\n",
       " 'though',\n",
       " 'enough',\n",
       " 'Sunday',\n",
       " 'Washington',\n",
       " 'late',\n",
       " 'added',\n",
       " 'always',\n",
       " 'Manhattan',\n",
       " 'chief',\n",
       " 'went',\n",
       " 'must',\n",
       " '4',\n",
       " 'young',\n",
       " 'building',\n",
       " 'asked',\n",
       " 'things',\n",
       " 'great',\n",
       " '15',\n",
       " '8',\n",
       " 'point',\n",
       " 'students',\n",
       " 'campaign',\n",
       " 'find',\n",
       " 'half',\n",
       " 'father',\n",
       " 'house',\n",
       " 'black',\n",
       " 'large',\n",
       " '11',\n",
       " 'P.M.',\n",
       " 'once',\n",
       " 'almost',\n",
       " 'really',\n",
       " 'known',\n",
       " 'look',\n",
       " 'Department',\n",
       " 'war',\n",
       " 'Some',\n",
       " 'power',\n",
       " 'again',\n",
       " 'give',\n",
       " 'already',\n",
       " 'six',\n",
       " 'sales',\n",
       " 'making',\n",
       " 'television',\n",
       " 'book',\n",
       " 'Net',\n",
       " '6',\n",
       " 'room',\n",
       " 'military',\n",
       " 'pay',\n",
       " 'So',\n",
       " 'others',\n",
       " 'real',\n",
       " 'job',\n",
       " 'support',\n",
       " 'news',\n",
       " 'times',\n",
       " '12',\n",
       " 'June',\n",
       " 'past',\n",
       " 'won',\n",
       " 'weeks',\n",
       " 'tax',\n",
       " 'Clinton',\n",
       " 'expected',\n",
       " 'industry',\n",
       " 'trying',\n",
       " 'report',\n",
       " 'different',\n",
       " 'mother',\n",
       " 'local',\n",
       " 'along',\n",
       " 'wife',\n",
       " 'change',\n",
       " 'Avenue',\n",
       " 'third',\n",
       " 'important',\n",
       " 'points',\n",
       " 'keep',\n",
       " 'Friday',\n",
       " 'film',\n",
       " 'top',\n",
       " 'held',\n",
       " 'Republican',\n",
       " 'open',\n",
       " 'service',\n",
       " 'line',\n",
       " 'issue',\n",
       " 'National',\n",
       " 'share',\n",
       " 'minutes',\n",
       " 'name',\n",
       " 'deal',\n",
       " 'history',\n",
       " 'court',\n",
       " 'national',\n",
       " 'lost',\n",
       " 'chairman',\n",
       " 'West',\n",
       " 'kind',\n",
       " 'games',\n",
       " 'free',\n",
       " 'became',\n",
       " 'himself',\n",
       " 'March',\n",
       " 'health',\n",
       " 'John',\n",
       " 'party',\n",
       " 'board',\n",
       " 'By',\n",
       " 'thought',\n",
       " 'players',\n",
       " 'information',\n",
       " 'No',\n",
       " 'World',\n",
       " 'played',\n",
       " 'stock',\n",
       " 'center',\n",
       " 'May',\n",
       " 'area',\n",
       " 'son',\n",
       " 'problem',\n",
       " 'thing',\n",
       " 'loss',\n",
       " 'hard',\n",
       " 'decision',\n",
       " 'problems',\n",
       " 'close',\n",
       " '25',\n",
       " 'woman',\n",
       " 'interest',\n",
       " 'Saturday',\n",
       " 'call',\n",
       " 'wanted',\n",
       " 'An',\n",
       " 'Now',\n",
       " 'lead',\n",
       " 'America',\n",
       " 'according',\n",
       " 'given',\n",
       " 'recently',\n",
       " 'working',\n",
       " 'care',\n",
       " '7',\n",
       " 'head',\n",
       " 'death',\n",
       " 'Congress',\n",
       " 'Center',\n",
       " 'Share',\n",
       " 'done',\n",
       " 'ever',\n",
       " 'water',\n",
       " 'led',\n",
       " 'earns',\n",
       " 'taken',\n",
       " 'died',\n",
       " 'A.',\n",
       " 'based',\n",
       " 'J.',\n",
       " 'art',\n",
       " 'official',\n",
       " 'saying',\n",
       " 'economic',\n",
       " 'start',\n",
       " 'seems',\n",
       " 'agency',\n",
       " 'course',\n",
       " 'series',\n",
       " 'move',\n",
       " 'having',\n",
       " 'private',\n",
       " 'p.m.',\n",
       " 'fact',\n",
       " 'New',\n",
       " '9',\n",
       " 'control',\n",
       " 'While',\n",
       " 'record',\n",
       " 'Inc.',\n",
       " 'reports',\n",
       " 'meeting',\n",
       " 'white',\n",
       " 'received',\n",
       " 'yet',\n",
       " 'works',\n",
       " 'New_York_City',\n",
       " 'cost',\n",
       " 'hours',\n",
       " 'general',\n",
       " 'makes',\n",
       " 'Tuesday',\n",
       " 'cut',\n",
       " 'plans',\n",
       " 'nearly',\n",
       " 'price',\n",
       " 'Court',\n",
       " 'example',\n",
       " '50',\n",
       " 'near',\n",
       " 'why',\n",
       " 'side',\n",
       " 'senior',\n",
       " 'leaders',\n",
       " 'Monday',\n",
       " 'seen',\n",
       " 'workers',\n",
       " 'nation',\n",
       " 'feel',\n",
       " 'Company',\n",
       " 'House',\n",
       " 'policy',\n",
       " 'however',\n",
       " 'together',\n",
       " \"'ll\",\n",
       " 'groups',\n",
       " 'Thursday',\n",
       " 'financial',\n",
       " 'behind',\n",
       " 'gave',\n",
       " 'doing',\n",
       " 'July',\n",
       " 'town',\n",
       " 'oil',\n",
       " '!',\n",
       " 'Is',\n",
       " 'COMPANY',\n",
       " 'Iraq',\n",
       " 'ca',\n",
       " 'include',\n",
       " 'summer',\n",
       " 'able',\n",
       " 'outside',\n",
       " 'programs',\n",
       " 'role',\n",
       " 'prices',\n",
       " 'budget',\n",
       " 'All',\n",
       " 'April',\n",
       " 'hit',\n",
       " 'quarter',\n",
       " 'food',\n",
       " 'across',\n",
       " 'believe',\n",
       " 'question',\n",
       " 'worked',\n",
       " 'Wednesday',\n",
       " 'Senate',\n",
       " 'turned',\n",
       " 'full',\n",
       " 'story',\n",
       " 'likely',\n",
       " 'announced',\n",
       " 'clear',\n",
       " 'started',\n",
       " 'probably',\n",
       " 'car',\n",
       " 'earnings',\n",
       " 'community',\n",
       " 'final',\n",
       " 'possible',\n",
       " 'seemed',\n",
       " 'New_Jersey',\n",
       " 'rather',\n",
       " 'nothing',\n",
       " 'themselves',\n",
       " 'trade',\n",
       " 'firm',\n",
       " 'sense',\n",
       " 'taking',\n",
       " 'future',\n",
       " 'face',\n",
       " 'within',\n",
       " 'special',\n",
       " 'live',\n",
       " 'schools',\n",
       " 'toward',\n",
       " 'increase',\n",
       " 'current',\n",
       " 'offer',\n",
       " 'David',\n",
       " 'strong',\n",
       " 'reported',\n",
       " 'leader',\n",
       " 'parents',\n",
       " 'force',\n",
       " 'Even',\n",
       " 'member',\n",
       " 'issues',\n",
       " 'return',\n",
       " 'services',\n",
       " 'drug',\n",
       " 'space',\n",
       " 'School',\n",
       " '\\\\*\\\\*',\n",
       " 'getting',\n",
       " 'bill',\n",
       " 'earlier',\n",
       " 'Robert',\n",
       " '100',\n",
       " 'daughter',\n",
       " 'rights',\n",
       " 'Brooklyn',\n",
       " 'turn',\n",
       " 'available',\n",
       " '40',\n",
       " 'Then',\n",
       " 'East',\n",
       " 'lawyer',\n",
       " 'From',\n",
       " 'love',\n",
       " 'vice',\n",
       " 'site',\n",
       " 'win',\n",
       " 'lives',\n",
       " 'anything',\n",
       " 'research',\n",
       " 'security',\n",
       " 'study',\n",
       " 'spokesman',\n",
       " 'Americans',\n",
       " 'playing',\n",
       " 'idea',\n",
       " 'person',\n",
       " 'buy',\n",
       " 'comes',\n",
       " 'try',\n",
       " 'rate',\n",
       " '\\\\*\\\\*\\\\*',\n",
       " 'Last',\n",
       " 'friends',\n",
       " 'especially',\n",
       " 'victory',\n",
       " 'REPORTS',\n",
       " '18',\n",
       " 'manager',\n",
       " 'itself',\n",
       " 'effort',\n",
       " 'looking',\n",
       " 'fall',\n",
       " 'process',\n",
       " 'economy',\n",
       " 'using',\n",
       " 'running',\n",
       " \"'d\",\n",
       " 'career',\n",
       " 'seem',\n",
       " 'foreign',\n",
       " 'vote',\n",
       " 'production',\n",
       " 'Senator',\n",
       " 'average',\n",
       " 'Her',\n",
       " 'wrote',\n",
       " 'agreed',\n",
       " 'agreement',\n",
       " 'period',\n",
       " 'Administration',\n",
       " 'age',\n",
       " 'Corporation',\n",
       " 'seven',\n",
       " 'feet',\n",
       " 'hand',\n",
       " 'My',\n",
       " 'interview',\n",
       " 'sold',\n",
       " '14',\n",
       " 'spent',\n",
       " 'Democratic',\n",
       " 'provide',\n",
       " 'Michael',\n",
       " 'cases',\n",
       " 'China',\n",
       " 'husband',\n",
       " 'shot',\n",
       " '13',\n",
       " 'brought',\n",
       " 'human',\n",
       " 'included',\n",
       " 'computer',\n",
       " 'French',\n",
       " 'view',\n",
       " 'front',\n",
       " 'costs',\n",
       " 'Mayor',\n",
       " 'race',\n",
       " 'field',\n",
       " 'performance',\n",
       " 'moved',\n",
       " 'named',\n",
       " 'Although',\n",
       " 'administration',\n",
       " 'result',\n",
       " 'Many',\n",
       " 'These',\n",
       " 'article',\n",
       " 'international',\n",
       " 'coming',\n",
       " 'child',\n",
       " 'needed',\n",
       " 'tried',\n",
       " 'talk',\n",
       " 'General',\n",
       " 'Democrats',\n",
       " 'charges',\n",
       " 'Not',\n",
       " 'project',\n",
       " '16',\n",
       " 'position',\n",
       " 'contract',\n",
       " 'countries',\n",
       " 'White_House',\n",
       " 'short',\n",
       " 'let',\n",
       " 'involved',\n",
       " 'development',\n",
       " 'order',\n",
       " 'morning',\n",
       " 'M.',\n",
       " 'calls',\n",
       " 'matter',\n",
       " 'air',\n",
       " 'personal',\n",
       " 'staff',\n",
       " 'officers',\n",
       " 'largest',\n",
       " 'continue',\n",
       " 'Israel',\n",
       " 'living',\n",
       " 'bad',\n",
       " 'shows',\n",
       " 'evidence',\n",
       " 'decided',\n",
       " 'soon',\n",
       " 'sure',\n",
       " 'action',\n",
       " 'helped',\n",
       " 'friend',\n",
       " 'higher',\n",
       " 'defense',\n",
       " 'offered',\n",
       " 'states',\n",
       " 'difficult',\n",
       " 'reason',\n",
       " 'rates',\n",
       " 'paid',\n",
       " 'saw',\n",
       " 'jobs',\n",
       " 'Council',\n",
       " 'level',\n",
       " 'either',\n",
       " 'sometimes',\n",
       " 'taxes',\n",
       " 'someone',\n",
       " 'sell',\n",
       " 'tell',\n",
       " 'heart',\n",
       " 'list',\n",
       " 'eight',\n",
       " 'single',\n",
       " 'knew',\n",
       " 'Japan',\n",
       " 'longer',\n",
       " 'bring',\n",
       " 'movie',\n",
       " 'coach',\n",
       " 'miles',\n",
       " 'everything',\n",
       " 'legal',\n",
       " 'Theater',\n",
       " '17',\n",
       " 'Editor',\n",
       " 'James',\n",
       " '31',\n",
       " 'killed',\n",
       " 'sent',\n",
       " 'player',\n",
       " 'Of',\n",
       " 'form',\n",
       " 'Association',\n",
       " 'leading',\n",
       " 'Most',\n",
       " 'changes',\n",
       " 'served',\n",
       " 'Two',\n",
       " 'investment',\n",
       " 'perhaps',\n",
       " 'ground',\n",
       " 'means',\n",
       " 'questions',\n",
       " 'built',\n",
       " 'shares',\n",
       " 'conference',\n",
       " 'light',\n",
       " 'leave',\n",
       " 'charge',\n",
       " 'felt',\n",
       " 'education',\n",
       " 'British',\n",
       " 'California',\n",
       " 'spending',\n",
       " 'runs',\n",
       " 'Republicans',\n",
       " 'social',\n",
       " 'experience',\n",
       " 'efforts',\n",
       " 'medical',\n",
       " 'hope',\n",
       " 'N.Y.',\n",
       " 'particularly',\n",
       " 'People',\n",
       " 'effect',\n",
       " 'officer',\n",
       " 'War',\n",
       " 'Sept.',\n",
       " 'chance',\n",
       " 'whole',\n",
       " 'includes',\n",
       " 'although',\n",
       " 'E.',\n",
       " 'books',\n",
       " 'college',\n",
       " 'International',\n",
       " 'attack',\n",
       " 'main',\n",
       " 'statement',\n",
       " 'bank',\n",
       " 'attention',\n",
       " 'employees',\n",
       " 'Notice',\n",
       " 'Jr.',\n",
       " 'Paid',\n",
       " 'growth',\n",
       " 'certain',\n",
       " 'residents',\n",
       " 'City',\n",
       " 'department',\n",
       " 'forces',\n",
       " 'Europe',\n",
       " '60',\n",
       " 'committee',\n",
       " 'election',\n",
       " 'whom',\n",
       " 'similar',\n",
       " 'begin',\n",
       " 'income',\n",
       " 'Japanese',\n",
       " '1990',\n",
       " 'Richard',\n",
       " 'U.S.',\n",
       " 'simply',\n",
       " 'William',\n",
       " 'created',\n",
       " 'else',\n",
       " 'takes',\n",
       " 'families',\n",
       " 'No.',\n",
       " 'funds',\n",
       " 'rest',\n",
       " 'S.',\n",
       " 'executives',\n",
       " 'growing',\n",
       " 'Yankees',\n",
       " 'allowed',\n",
       " 'serious',\n",
       " 'organization',\n",
       " 'operations',\n",
       " 'stop',\n",
       " 'federal',\n",
       " '24',\n",
       " 'ended',\n",
       " 'fell',\n",
       " 'hold',\n",
       " 'opened',\n",
       " 'trial',\n",
       " 'appeared',\n",
       " 'needs',\n",
       " 'ways',\n",
       " 'wants',\n",
       " 'lawyers',\n",
       " 'lower',\n",
       " 'telephone',\n",
       " 'meet',\n",
       " 'land',\n",
       " 'How',\n",
       " 'body',\n",
       " 'union',\n",
       " 'investors',\n",
       " 'am',\n",
       " 'teams',\n",
       " 'low',\n",
       " 'read',\n",
       " 'raised',\n",
       " 'technology',\n",
       " 'total',\n",
       " 'showed',\n",
       " 'considered',\n",
       " 'popular',\n",
       " 'described',\n",
       " 'judge',\n",
       " 'goal',\n",
       " 'store',\n",
       " 'capital',\n",
       " 'met',\n",
       " 'Deaths',\n",
       " 'areas',\n",
       " 'rules',\n",
       " 'results',\n",
       " 'addition',\n",
       " 'further',\n",
       " 'Justice',\n",
       " 'European',\n",
       " 'London',\n",
       " 'Board',\n",
       " 'continued',\n",
       " 'quickly',\n",
       " 'stage',\n",
       " 'instead',\n",
       " 'create',\n",
       " 'Chicago',\n",
       " 'allow',\n",
       " 'A.M.',\n",
       " 'usually',\n",
       " 'released',\n",
       " 'words',\n",
       " 'professor',\n",
       " 'couple',\n",
       " 'everyone',\n",
       " 'de',\n",
       " 'floor',\n",
       " 'English',\n",
       " 'beginning',\n",
       " 'ball',\n",
       " 'fire',\n",
       " 'Internet',\n",
       " 'common',\n",
       " 'anyone',\n",
       " 'Still',\n",
       " 'Since',\n",
       " 'apartment',\n",
       " 'United_Nations',\n",
       " 'street',\n",
       " 'Broadway',\n",
       " 'insurance',\n",
       " 'management',\n",
       " 'pressure',\n",
       " 'restaurant',\n",
       " 'heard',\n",
       " 'evening',\n",
       " 'Thomas',\n",
       " 'More',\n",
       " 'remain',\n",
       " 'mind',\n",
       " 'latest',\n",
       " 'fight',\n",
       " 'Los_Angeles',\n",
       " 'South',\n",
       " 'goes',\n",
       " 'annual',\n",
       " 'First',\n",
       " 'terms',\n",
       " 'products',\n",
       " '22',\n",
       " 'Soviet',\n",
       " 'opening',\n",
       " 'experts',\n",
       " 'above',\n",
       " 'closed',\n",
       " 'proposed',\n",
       " 'Minister',\n",
       " 'investigation',\n",
       " '19',\n",
       " 'written',\n",
       " 'Party',\n",
       " 'R.',\n",
       " 'buildings',\n",
       " 'stay',\n",
       " 'poor',\n",
       " 'Judge',\n",
       " 'style',\n",
       " 'theater',\n",
       " '21',\n",
       " ...]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist.extend(wlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw2v = open(w2v_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "fw2v = [line for line in fw2v]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-0.221001',\n",
       " '1.358701',\n",
       " '-0.747914',\n",
       " '0.870552',\n",
       " '1.417721',\n",
       " '0.009870',\n",
       " '-0.614740',\n",
       " '1.618770',\n",
       " '0.648751',\n",
       " '0.390447',\n",
       " '0.478752',\n",
       " '-0.383416',\n",
       " '1.196540',\n",
       " '-0.644879',\n",
       " '-0.421608',\n",
       " '-0.923521',\n",
       " '0.361792',\n",
       " '-0.859179',\n",
       " '0.224276',\n",
       " '1.084490',\n",
       " '0.834912',\n",
       " '-0.257614',\n",
       " '-0.248996',\n",
       " '-1.236610',\n",
       " '1.638060',\n",
       " '0.720808',\n",
       " '1.066176',\n",
       " '-0.369189',\n",
       " '1.228255',\n",
       " '-0.155706',\n",
       " '0.748299',\n",
       " '-0.069667',\n",
       " '1.141663',\n",
       " '-0.488700',\n",
       " '2.208251',\n",
       " '-0.090331',\n",
       " '1.176398',\n",
       " '-0.632925',\n",
       " '0.334784',\n",
       " '-1.695715',\n",
       " '0.873845',\n",
       " '-0.801254',\n",
       " '-0.000435',\n",
       " '-0.600301',\n",
       " '2.363796',\n",
       " '-0.249681',\n",
       " '0.473764',\n",
       " '0.503697',\n",
       " '0.690691',\n",
       " '-0.513487']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line1 = fw2v[0].strip('\\n').split()\n",
    "line1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.221001,\n",
       " 1.358701,\n",
       " -0.747914,\n",
       " 0.870552,\n",
       " 1.417721,\n",
       " 0.00987,\n",
       " -0.61474,\n",
       " 1.61877,\n",
       " 0.648751,\n",
       " 0.390447,\n",
       " 0.478752,\n",
       " -0.383416,\n",
       " 1.19654,\n",
       " -0.644879,\n",
       " -0.421608,\n",
       " -0.923521,\n",
       " 0.361792,\n",
       " -0.859179,\n",
       " 0.224276,\n",
       " 1.08449,\n",
       " 0.834912,\n",
       " -0.257614,\n",
       " -0.248996,\n",
       " -1.23661,\n",
       " 1.63806,\n",
       " 0.720808,\n",
       " 1.066176,\n",
       " -0.369189,\n",
       " 1.228255,\n",
       " -0.155706,\n",
       " 0.748299,\n",
       " -0.069667,\n",
       " 1.141663,\n",
       " -0.4887,\n",
       " 2.208251,\n",
       " -0.090331,\n",
       " 1.176398,\n",
       " -0.632925,\n",
       " 0.334784,\n",
       " -1.695715,\n",
       " 0.873845,\n",
       " -0.801254,\n",
       " -0.000435,\n",
       " -0.600301,\n",
       " 2.363796,\n",
       " -0.249681,\n",
       " 0.473764,\n",
       " 0.503697,\n",
       " 0.690691,\n",
       " -0.513487]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(float, line1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for line in open(w2v_path):\n",
    "    line = line.strip('\\n').split()\n",
    "    vec = list(map(float, line))\n",
    "    vecs.append(vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160695"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim = len(vecs[0])\n",
    "dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs.insert(0, np.zeros(dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordlist.append('UNK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UNK'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordlist[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs.append(np.random.uniform(low=-1.0, high=1.0, size=dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = {j: i for i, j in enumerate(wordlist)}\n",
    "id2word = {i: j for i, j in enumerate(wordlist)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = np.array(vecs, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "初始化position2vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 50\n",
    "pos_dim = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos1_vec = np.asarray(np.random.uniform(low=-1.0, high=1.0, size=(limit * 2 + 1, pos_dim)), dtype=np.float32)\n",
    "pos1_vec = np.vstack((np.zeros((1, pos_dim)), pos1_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos2_vec = np.asarray(np.random.uniform(low=-1.0, high=1.0, size=(limit * 2 + 1, pos_dim)), dtype=np.float32)\n",
    "pos2_vec = np.vstack((np.zeros((1, pos_dim)), pos2_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(102, 5)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos1_vec.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(opt.data_root, 'w2v.npy'), vecs)\n",
    "np.save(os.path.join(opt.data_root, 'p1_2v.npy'), pos1_vec)\n",
    "np.save(os.path.join(opt.data_root, 'p2_2v.npy'), pos2_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预处理训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sens =[]\n",
    "all_labels =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1122 53041\\n'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1122, 53041]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entities = list(map(int, line.split(' ')))\n",
    "entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1 -1 -1 -1 10\\n'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = f.readline()\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '-1', '-1', '-1', '10\\n']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bagLabel = line.split(' ')\n",
    "bagLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, -1, -1, -1]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rel = list(map(int, bagLabel[0:-1]))\n",
    "rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = int(bagLabel[-1])   #句子个数\n",
    "num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = []\n",
    "sentences = []\n",
    "entitiesPos = []\n",
    "masks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15',\n",
       " '13',\n",
       " '16842',\n",
       " '125741',\n",
       " '1',\n",
       " '2',\n",
       " '619',\n",
       " '4',\n",
       " '16297',\n",
       " '1005',\n",
       " '125741',\n",
       " '7',\n",
       " '3320',\n",
       " '125741',\n",
       " '4',\n",
       " '53041',\n",
       " '1',\n",
       " '1122',\n",
       " '1',\n",
       " '17',\n",
       " '1067',\n",
       " '173',\n",
       " '1144',\n",
       " '5',\n",
       " '10199',\n",
       " '968',\n",
       " '1421',\n",
       " '114169',\n",
       " '1',\n",
       " '6',\n",
       " '440',\n",
       " '4',\n",
       " '12045',\n",
       " '1354',\n",
       " '114169',\n",
       " '7',\n",
       " '2554',\n",
       " '15237',\n",
       " '4130',\n",
       " '737',\n",
       " '114169',\n",
       " '4',\n",
       " '17304',\n",
       " '1',\n",
       " '1278',\n",
       " '3']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent = f.readline().strip().split(' ')\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Rosemary',\n",
       " 'Antonelle',\n",
       " ',',\n",
       " 'the',\n",
       " 'daughter',\n",
       " 'of',\n",
       " 'Teresa',\n",
       " 'L.',\n",
       " 'Antonelle',\n",
       " 'and',\n",
       " 'Patrick',\n",
       " 'Antonelle',\n",
       " 'of',\n",
       " 'Belle_Harbor',\n",
       " ',',\n",
       " 'Queens',\n",
       " ',',\n",
       " 'was',\n",
       " 'married',\n",
       " 'yesterday',\n",
       " 'afternoon',\n",
       " 'to',\n",
       " 'Lt.',\n",
       " 'Thomas',\n",
       " 'Joseph',\n",
       " 'Quast',\n",
       " ',',\n",
       " 'a',\n",
       " 'son',\n",
       " 'of',\n",
       " 'Peggy',\n",
       " 'B.',\n",
       " 'Quast',\n",
       " 'and',\n",
       " 'Vice',\n",
       " 'Adm.',\n",
       " 'Philip',\n",
       " 'M.',\n",
       " 'Quast',\n",
       " 'of',\n",
       " 'Carmel',\n",
       " ',',\n",
       " 'Calif.',\n",
       " '.']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = list(map(lambda x: id2word[int(x)], sent[2:]))\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[16, 14]]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions.append(list(map(int, sent[0:2])))\n",
    "positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[16, 14]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epos = list(map(lambda x: int(x) + 1, sent[0:2]))\n",
    "epos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[14, 16]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epos.sort()\n",
    "epos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = [1] * (epos[0] + 1)\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask += [2] * (epos[1] - epos[0])\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 1,\n",
       " 2,\n",
       " 2,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3]"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask += [3] * (len(sent[2:-1]) - epos[1])\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[14, 16]]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entitiesPos.append(epos)\n",
    "entitiesPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[16842,\n",
       "  125741,\n",
       "  1,\n",
       "  2,\n",
       "  619,\n",
       "  4,\n",
       "  16297,\n",
       "  1005,\n",
       "  125741,\n",
       "  7,\n",
       "  3320,\n",
       "  125741,\n",
       "  4,\n",
       "  53041,\n",
       "  1,\n",
       "  1122,\n",
       "  1,\n",
       "  17,\n",
       "  1067,\n",
       "  173,\n",
       "  1144,\n",
       "  5,\n",
       "  10199,\n",
       "  968,\n",
       "  1421,\n",
       "  114169,\n",
       "  1,\n",
       "  6,\n",
       "  440,\n",
       "  4,\n",
       "  12045,\n",
       "  1354,\n",
       "  114169,\n",
       "  7,\n",
       "  2554,\n",
       "  15237,\n",
       "  4130,\n",
       "  737,\n",
       "  114169,\n",
       "  4,\n",
       "  17304,\n",
       "  1,\n",
       "  1278]]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences.append(list(map(int, sent[2:-1])))\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3,\n",
       "  3]]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masks.append(mask)\n",
    "masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 载入预处理后的数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = os.path.join(opt.data_root, 'train/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load(path + 'bags_feature.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1122, 53041]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(path + 'labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1, -1, -1],\n",
       "       [ 3, -1, -1, -1],\n",
       "       [ 5,  2, -1, -1],\n",
       "       ...,\n",
       "       [ 0, -1, -1, -1],\n",
       "       [ 0, -1, -1, -1],\n",
       "       [ 0, -1, -1, -1]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2构建dataset类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataModel = getattr(dataset, opt.data + 'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataset.filternyt.FilterNYTData"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FilterNYTData(Dataset):\n",
    "\n",
    "    def __init__(self, root_path, train=True):\n",
    "        if train:\n",
    "            path = os.path.join(root_path, 'train/')\n",
    "            print('loading train data')\n",
    "        else:\n",
    "            path = os.path.join(root_path, 'test/')\n",
    "            print('loading test data')\n",
    "\n",
    "        self.labels = np.load(path + 'labels.npy')\n",
    "        self.data = np.load(path + 'bags_feature.npy', allow_pickle=True)\n",
    "\n",
    "        print('loading finish')\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        assert idx < len(self.data)\n",
    "        return self.data[idx], self.labels[idx]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading train data\n",
      "loading finish\n"
     ]
    }
   ],
   "source": [
    "train_data = DataModel(opt.data_root, train=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    data, label = zip(*batch)\n",
    "    return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(train_data, opt.batch_size, shuffle=True, num_workers=opt.num_workers, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test data\n",
      "loading finish\n",
      "train data: 65726; test data: 93574\n"
     ]
    }
   ],
   "source": [
    "test_data = DataModel(opt.data_root, train=False)\n",
    "test_data_loader = DataLoader(test_data, batch_size=opt.batch_size, shuffle=False, num_workers=opt.num_workers, collate_fn=collate_fn)\n",
    "print('train data: {}; test data: {}'.format(len(train_data), len(test_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 模型定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if opt.use_gpu:\n",
    "    torch.cuda.set_device(opt.gpu_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = getattr(models, 'PCNN_ONE')(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicModule(torch.nn.Module):\n",
    "    '''\n",
    "    封装了nn.Module,主要是提供了save和load两个方法\n",
    "    '''\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BasicModule, self).__init__()\n",
    "        self.model_name=str(type(self))  # model name\n",
    "\n",
    "    def load(self, path):\n",
    "        '''\n",
    "        可加载指定路径的模型\n",
    "        '''\n",
    "        self.load_state_dict(torch.load(path))\n",
    "\n",
    "    def save(self, name=None):\n",
    "        '''\n",
    "        保存模型，默认使用“模型名字+时间”作为文件名\n",
    "        '''\n",
    "        prefix = 'checkpoints/'\n",
    "        if name is None:\n",
    "            name = prefix + self.model_name + '_'\n",
    "            name = time.strftime(name + '%m%d_%H:%M:%S.pth')\n",
    "        else:\n",
    "            name = prefix + self.model_name + '_' + str(name)+ '.pth'\n",
    "        torch.save(self.state_dict(), name)\n",
    "        return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCNN_ONE(BasicModule):\n",
    "    '''\n",
    "    Zeng 2015 DS PCNN\n",
    "    '''\n",
    "    def __init__(self, opt):\n",
    "        super(PCNN_ONE, self).__init__()\n",
    "\n",
    "        self.opt = opt\n",
    "\n",
    "        self.model_name = 'PCNN_ONE'\n",
    "\n",
    "        self.word_embs = nn.Embedding(self.opt.vocab_size, self.opt.word_dim)\n",
    "        self.pos1_embs = nn.Embedding(self.opt.pos_size, self.opt.pos_dim)\n",
    "        self.pos2_embs = nn.Embedding(self.opt.pos_size, self.opt.pos_dim)\n",
    "\n",
    "        feature_dim = self.opt.word_dim + self.opt.pos_dim * 2\n",
    "\n",
    "        # for more filter size\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, self.opt.filters_num, (k, feature_dim), padding=(int(k / 2), 0)) for k in self.opt.filters])\n",
    "\n",
    "        all_filter_num = self.opt.filters_num * len(self.opt.filters)\n",
    "\n",
    "        if self.opt.use_pcnn:\n",
    "            all_filter_num = all_filter_num * 3\n",
    "            masks = torch.FloatTensor(([[0, 0, 0], [1, 0, 0], [0, 1, 0], [0, 0, 1]]))\n",
    "            if self.opt.use_gpu:\n",
    "                masks = masks.cuda()\n",
    "            self.mask_embedding = nn.Embedding(4, 3)\n",
    "            self.mask_embedding.weight.data.copy_(masks)\n",
    "            self.mask_embedding.weight.requires_grad = False\n",
    "\n",
    "        self.linear = nn.Linear(all_filter_num, self.opt.rel_num)\n",
    "        self.dropout = nn.Dropout(self.opt.drop_out)\n",
    "\n",
    "        self.init_model_weight()\n",
    "        self.init_word_emb()\n",
    "\n",
    "    def init_model_weight(self):\n",
    "        '''\n",
    "        use xavier to init\n",
    "        '''\n",
    "        for conv in self.convs:\n",
    "            nn.init.xavier_uniform_(conv.weight)\n",
    "            nn.init.constant_(conv.bias, 0.0)\n",
    "\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "        nn.init.constant_(self.linear.bias, 0.0)\n",
    "\n",
    "    def init_word_emb(self):\n",
    "\n",
    "        def p_2norm(path):\n",
    "            v = torch.from_numpy(np.load(path))\n",
    "            if self.opt.norm_emb:\n",
    "                v = torch.div(v, v.norm(2, 1).unsqueeze(1))\n",
    "                v[v != v] = 0.0\n",
    "            return v\n",
    "\n",
    "        w2v = p_2norm(self.opt.w2v_path)\n",
    "        p1_2v = p_2norm(self.opt.p1_2v_path)\n",
    "        p2_2v = p_2norm(self.opt.p2_2v_path)\n",
    "\n",
    "        if self.opt.use_gpu:\n",
    "            self.word_embs.weight.data.copy_(w2v.cuda())\n",
    "            self.pos1_embs.weight.data.copy_(p1_2v.cuda())\n",
    "            self.pos2_embs.weight.data.copy_(p2_2v.cuda())\n",
    "        else:\n",
    "            self.pos1_embs.weight.data.copy_(p1_2v)\n",
    "            self.pos2_embs.weight.data.copy_(p2_2v)\n",
    "            self.word_embs.weight.data.copy_(w2v)\n",
    "\n",
    "    def mask_piece_pooling(self, x, mask):\n",
    "        '''\n",
    "        refer: https://github.com/thunlp/OpenNRE\n",
    "        A fast piecewise pooling using mask\n",
    "        '''\n",
    "        x = x.unsqueeze(-1).permute(0, 2, 1, -1)\n",
    "        masks = self.mask_embedding(mask).unsqueeze(-2) * 100\n",
    "        x = masks.float() + x\n",
    "        x = torch.max(x, 1)[0] - torch.FloatTensor([100]).cuda()\n",
    "        x = x.view(-1, x.size(1) * x.size(2))\n",
    "        return x\n",
    "\n",
    "    def piece_max_pooling(self, x, insPool):\n",
    "        '''\n",
    "        old version piecewise\n",
    "        '''\n",
    "        split_batch_x = torch.split(x, 1, 0)\n",
    "        split_pool = torch.split(insPool, 1, 0)\n",
    "        batch_res = []\n",
    "        for i in range(len(split_pool)):\n",
    "            ins = split_batch_x[i].squeeze()  # all_filter_num * max_len\n",
    "            pool = split_pool[i].squeeze().data    # 2\n",
    "            seg_1 = ins[:, :pool[0]].max(1)[0].unsqueeze(1)          # all_filter_num * 1\n",
    "            seg_2 = ins[:, pool[0]: pool[1]].max(1)[0].unsqueeze(1)  # all_filter_num * 1\n",
    "            seg_3 = ins[:, pool[1]:].max(1)[0].unsqueeze(1)\n",
    "            piece_max_pool = torch.cat([seg_1, seg_2, seg_3], 1).view(1, -1)    # 1 * 3all_filter_num\n",
    "            batch_res.append(piece_max_pool)\n",
    "\n",
    "        out = torch.cat(batch_res, 0)\n",
    "        assert out.size(1) == 3 * self.opt.filters_num\n",
    "        return out\n",
    "\n",
    "    def forward(self, x, train=False):\n",
    "\n",
    "        insEnt, _, insX, insPFs, insPool, insMasks = x\n",
    "        insPF1, insPF2 = [i.squeeze(1) for i in torch.split(insPFs, 1, 1)]\n",
    "\n",
    "        word_emb = self.word_embs(insX)\n",
    "        pf1_emb = self.pos1_embs(insPF1)\n",
    "        pf2_emb = self.pos2_embs(insPF2)\n",
    "\n",
    "        x = torch.cat([word_emb, pf1_emb, pf2_emb], 2)\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        x = [conv(x).squeeze(3) for conv in self.convs]\n",
    "        if self.opt.use_pcnn:\n",
    "            x = [self.mask_piece_pooling(i, insMasks) for i in x]\n",
    "            # x = [self.piece_max_pooling(i, insPool) for i in x]\n",
    "        else:\n",
    "            x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]\n",
    "        x = torch.cat(x, 1).tanh()\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.use_gpu:\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCNN_ONE(\n",
       "  (word_embs): Embedding(160697, 50)\n",
       "  (pos1_embs): Embedding(102, 5)\n",
       "  (pos2_embs): Embedding(102, 5)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 230, kernel_size=(3, 60), stride=(1, 1), padding=(1, 0))\n",
       "  )\n",
       "  (mask_embedding): Embedding(4, 3)\n",
       "  (linear): Linear(in_features=690, out_features=27, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adadelta(filter(lambda p: p.requires_grad, model.parameters()), rho=1.0, eps=1e-6, weight_decay=opt.weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n"
     ]
    }
   ],
   "source": [
    "print(\"start training...\")\n",
    "max_pre = -1.0\n",
    "max_rec = -1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label_set = iter(train_data_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([135834, 26554]), 3,\n",
       "       list([[26554, 11, 326, 303, 1, 135834, 1, 15, 9, 32, 683, 10, 176, 4, 2, 1865, 196, 46, 187, 5, 26554, 906, 34, 37, 1815, 65, 41, 810, 13723, 89, 2758, 17, 1987, 9, 1807, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [135, 987, 1865, 2129, 6, 308, 15011, 9, 26554, 11, 3478, 7, 6, 1424, 4219, 4, 2, 2018, 72, 29, 115, 23, 6, 113, 1, 8, 26554, 11, 326, 303, 1, 135834, 1, 15, 9, 6, 844, 535, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4849, 15, 10, 85, 522, 4, 26554, 1, 18, 135834, 1, 6, 215, 521, 303, 19, 2, 51104, 1101, 2471, 1, 23, 326, 303, 1, 37, 115, 2018, 9, 9188, 5033, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       "       list([[[47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], [[43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]),\n",
       "       list([[1, 6], [27, 32], [7, 10]]),\n",
       "       list([[1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 4, -1, -1, -1])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_set[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = [l[0] for l in label_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.use_gpu:\n",
    "    label = torch.LongTensor(label).cuda()\n",
    "else:\n",
    "    label = torch.LongTensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_instance(model, batch_data, labels):\n",
    "\n",
    "    model.eval()\n",
    "    select_ent = []\n",
    "    select_num = []\n",
    "    select_sen = []\n",
    "    select_pf = []\n",
    "    select_pool = []\n",
    "    select_mask = []\n",
    "    for idx, bag in enumerate(batch_data):\n",
    "        insNum = bag[1]\n",
    "        label = labels[idx]\n",
    "        max_ins_id = 0\n",
    "        if insNum > 1:\n",
    "            model.batch_size = insNum\n",
    "            if opt.use_gpu:\n",
    "                data = map(lambda x: torch.LongTensor(x).cuda(), bag)\n",
    "            else:\n",
    "                data = map(lambda x: torch.LongTensor(x), bag)\n",
    "\n",
    "            out = model(data)\n",
    "\n",
    "            #  max_ins_id = torch.max(torch.max(out, 1)[0], 0)[1]\n",
    "            max_ins_id = torch.max(out[:, label], 0)[1]\n",
    "\n",
    "            if opt.use_gpu:\n",
    "                #  max_ins_id = max_ins_id.data.cpu().numpy()[0]\n",
    "                max_ins_id = max_ins_id.item()\n",
    "            else:\n",
    "                max_ins_id = max_ins_id.data.numpy()[0]\n",
    "\n",
    "        max_sen = bag[2][max_ins_id]\n",
    "        max_pf = bag[3][max_ins_id]\n",
    "        max_pool = bag[4][max_ins_id]\n",
    "        max_mask = bag[5][max_ins_id]\n",
    "\n",
    "        select_ent.append(bag[0])\n",
    "        select_num.append(bag[1])\n",
    "        select_sen.append(max_sen)\n",
    "        select_pf.append(max_pf)\n",
    "        select_pool.append(max_pool)\n",
    "        select_mask.append(max_mask)\n",
    "\n",
    "    if opt.use_gpu:\n",
    "        data = map(lambda x: torch.LongTensor(x).cuda(), [select_ent, select_num, select_sen, select_pf, select_pool, select_mask])\n",
    "    else:\n",
    "        data = map(lambda x: torch.LongTensor(x), [select_ent, select_num, select_sen, select_pf, select_pool, select_mask])\n",
    "\n",
    "    model.train()\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ = select_instance(model, data, label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select_instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCNN_ONE(\n",
       "  (word_embs): Embedding(160697, 50)\n",
       "  (pos1_embs): Embedding(102, 5)\n",
       "  (pos2_embs): Embedding(102, 5)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 230, kernel_size=(3, 60), stride=(1, 1), padding=(1, 0))\n",
       "  )\n",
       "  (mask_embedding): Embedding(4, 3)\n",
       "  (linear): Linear(in_features=690, out_features=27, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_ent = []\n",
    "select_num = []\n",
    "select_sen = []\n",
    "select_pf = []\n",
    "select_pool = []\n",
    "select_mask = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bag  = data[1]\n",
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1856, 4689]), 1,\n",
       "       list([[1856, 17, 32, 18674, 396, 1090, 9, 2, 27330, 75, 4, 90, 72, 107, 197, 23, 181, 7163, 1, 8, 15, 24321, 40559, 1, 2, 180, 4, 4689, 694, 26, 4252, 5, 1362, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]),\n",
       "       list([[[52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]]),\n",
       "       list([[1, 28]]),\n",
       "       list([[1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "insNum = bag[1]\n",
    "insNum     # instacne 的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1, -1, -1, -1],\n",
       "       [ 3, -1, -1, -1],\n",
       "       [ 5,  2, -1, -1],\n",
       "       ...,\n",
       "       [ 0, -1, -1, -1],\n",
       "       [ 0, -1, -1, -1],\n",
       "       [ 0, -1, -1, -1]])"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1, -1])"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label = labels[idx]\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ins_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if insNum > 1:\n",
    "model.batch_size = insNum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "if opt.use_gpu:\n",
    "    data = map(lambda x: torch.LongTensor(x).cuda(), bag)\n",
    "else:\n",
    "    data = map(lambda x: torch.LongTensor(x), bag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0147, -0.0539,  0.0280,  0.0557, -0.0702, -0.0361, -0.1082,  0.1344,\n",
       "         -0.0356,  0.0322,  0.0777, -0.0261,  0.0630,  0.0317,  0.0254,  0.0164,\n",
       "          0.0426, -0.0248,  0.0536, -0.0229, -0.0469, -0.0333,  0.0104, -0.0498,\n",
       "          0.0359, -0.0025, -0.0397]], device='cuda:1', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(data)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 27])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape    # 3个instance , 27种关系"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1, -1, -1, -1])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0539, -0.0397, -0.0397, -0.0397]], device='cuda:1',\n",
       "       grad_fn=<IndexBackward>)"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[:, label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0], device='cuda:1')"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ins_id = torch.max(out[:, label], 0)[1]   \n",
    "max_ins_id    # 选出选择一个最后评分最大的，作为使用的instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ins_id = max_ins_id.data.cpu().numpy()[0]\n",
    "max_ins_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sen = bag[2][max_ins_id]\n",
    "max_pf = bag[3][max_ins_id]\n",
    "max_pool = bag[4][max_ins_id]\n",
    "max_mask = bag[5][max_ins_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "select_ent.append(bag[0])\n",
    "select_num.append(bag[1])\n",
    "select_sen.append(max_sen)\n",
    "select_pf.append(max_pf)\n",
    "select_pool.append(max_pool)\n",
    "select_mask.append(max_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCNN_ONE(\n",
       "  (word_embs): Embedding(160697, 50)\n",
       "  (pos1_embs): Embedding(102, 5)\n",
       "  (pos2_embs): Embedding(102, 5)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 230, kernel_size=(3, 60), stride=(1, 1), padding=(1, 0))\n",
       "  )\n",
       "  (mask_embedding): Embedding(4, 3)\n",
       "  (linear): Linear(in_features=690, out_features=27, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if opt.use_gpu:\n",
    "    data = map(lambda x: torch.LongTensor(x).cuda(), [select_ent, select_num, select_sen, select_pf, select_pool, select_mask])\n",
    "else:\n",
    "    data = map(lambda x: torch.LongTensor(x), [select_ent, select_num, select_sen, select_pf, select_pool, select_mask])\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "select_instance结束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batch_size = opt.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1526,  0.0134, -0.0232,  ...,  0.0203,  0.0284,  0.0130],\n",
       "        [ 0.0147, -0.0521,  0.0131,  ...,  0.1512,  0.0764,  0.0140],\n",
       "        [-0.7913,  0.2031,  0.7932,  ...,  0.0539,  1.5673, -1.9126],\n",
       "        ...,\n",
       "        [-0.0359, -0.1471, -0.1216,  ...,  0.1467,  0.0576, -0.0958],\n",
       "        [ 0.0642, -0.1000, -0.0797,  ...,  0.0435, -0.0413, -0.0175],\n",
       "        [ 0.1598, -0.0536,  0.0660,  ...,  0.1856,  0.0513, -0.1404]],\n",
       "       device='cuda:1', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = model(data_, train=True)\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 模型评价"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.1 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCNN_ONE(\n",
       "  (word_embs): Embedding(160697, 50)\n",
       "  (pos1_embs): Embedding(102, 5)\n",
       "  (pos2_embs): Embedding(102, 5)\n",
       "  (convs): ModuleList(\n",
       "    (0): Conv2d(1, 230, kernel_size=(3, 60), stride=(1, 1), padding=(1, 0))\n",
       "  )\n",
       "  (mask_embedding): Embedding(4, 3)\n",
       "  (linear): Linear(in_features=690, out_features=27, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = []\n",
    "true_y = []\n",
    "pred_p = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = iter(test_data_loader).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "insNum = bag[1]\n",
    "model.batch_size = insNum\n",
    "if opt.use_gpu:\n",
    "    data = map(lambda x: torch.LongTensor(x).cuda(), bag)\n",
    "else:\n",
    "    data = map(lambda x: torch.LongTensor(x), bag)\n",
    "\n",
    "out = model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 27])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = F.softmax(out, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_ins_prob, max_ins_label = map(lambda x: x.data.cpu().numpy(), torch.max(out, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04105159, 0.04166167], dtype=float32)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ins_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  7])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ins_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_prob = -1.0\n",
    "tmp_NA_prob = -1.0\n",
    "pred_label = 0\n",
    "pos_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_ins_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(insNum):\n",
    "    if pos_flag and max_ins_label[i] < 1:\n",
    "        continue\n",
    "    else:\n",
    "        if max_ins_label[i] > 0:\n",
    "            pos_flag = True\n",
    "            if max_ins_prob[i] > tmp_prob:\n",
    "                pred_label = max_ins_label[i]\n",
    "                tmp_prob = max_ins_prob[i]\n",
    "        else:\n",
    "            if max_ins_prob[i] > tmp_NA_prob:\n",
    "                tmp_NA_prob = max_ins_prob[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "if pos_flag:\n",
    "    pred_p.append(tmp_prob)\n",
    "else:\n",
    "    pred_p.append(tmp_NA_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y.append(pred_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.5.2 指标计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (data, labels) in enumerate(test_data_loader):\n",
    "    true_y.extend(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_num = len([i for i in true_y if i[0] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3464"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.04581885, 0.04166167]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(pred_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.argsort(pred_p)[::-1]\n",
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "all_pre = [0]\n",
    "all_rec = [0]\n",
    "fp_res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = true_y[index[idx]]\n",
    "j = pred_y[index[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, -1, -1, -1])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "if i[0] == 0:  # NA relation\n",
    "    if j > 0:\n",
    "        fp_res.append((index[idx], j, pred_p[index[idx]]))\n",
    "        fp += 1\n",
    "else:\n",
    "    if j == 0:\n",
    "        fn += 1\n",
    "    else:\n",
    "        for k in i:\n",
    "            if k == -1:\n",
    "                break\n",
    "            if k == j:\n",
    "                tp += 1\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    " if fp + tp == 0:\n",
    "    precision = 1.0\n",
    "else:\n",
    "    precision = tp * 1.0 / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "recall = tp * 1.0 / positive_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "if precision != all_pre[-1] or recall != all_rec[-1]:\n",
    "    all_pre.append(precision)\n",
    "    all_rec.append(recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 代码梳理及细节回顾(在VScode中演示)\n",
    "\n",
    "　　在VScode环境中的训练文件里再回顾训练流程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 作业\n",
    "  \n",
    "`【思考题】`思考这篇文章的模型在卷积神经网络方面以及多实例学习方面（损失函数），还有什么可以改进的地方吗，\n",
    "\n",
    "`【代码实践】`复现该文章代码的模型的PCNNs部分, 以及损失函数的部分（select_instance）。\n",
    "\n",
    "`【画图】`不看文章原图，按照自己的理解画出模型整体的结构图。\n",
    "\n",
    "`【总结】`对这篇文章进行回顾总结，思考并学习文章写作总体结构，学习实验设计等内容。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PYTH_1.6",
   "language": "python",
   "name": "pyth_1.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
